{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-accordance",
   "metadata": {},
   "source": [
    "# Linear Search\n",
    "\n",
    "- $O(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search(data, val):\n",
    "    process_count = 0\n",
    "    for i, datum in enumerate(data):\n",
    "        process_count += 1\n",
    "        if datum == val:\n",
    "            return True, i, process_count\n",
    "    return False, None, process_count\n",
    "\n",
    "data = list(range(1000))\n",
    "random.shuffle(data)\n",
    "\n",
    "print(linear_search(data, 0))\n",
    "print(linear_search(data, 500))\n",
    "print(linear_search(data, 999))\n",
    "print(linear_search(data, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-technical",
   "metadata": {},
   "source": [
    "# Binary Search\n",
    "\n",
    "- $O(\\log_2{n})$\n",
    "\n",
    "ソートしておけば中央値を見て片側に(半分に)絞っていけるじゃん、というシンプルで強力な考え"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-water",
   "metadata": {},
   "source": [
    "## recursive\n",
    "\n",
    "- 意外と再帰使う方が複雑なコードになってしまった、、これなら再帰使わない方がスマートかも、、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(data, val, process_count = 0):\n",
    "    \"\"\"data must be sorted\"\"\"\n",
    "    process_count += 1\n",
    "    center_index = len(data) // 2\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return False, None, process_count\n",
    "    if center_index == 0:\n",
    "        if val == data[center_index]:\n",
    "            return True, center_index, process_count\n",
    "        return False, None, process_count\n",
    "    \n",
    "    if val < data[center_index]:\n",
    "        return binary_search(data[:center_index], val, process_count)\n",
    "    elif data[center_index] < val:\n",
    "        is_found, index, count = binary_search(data[center_index + 1:], val, process_count)\n",
    "        return is_found, center_index + 1 + index if is_found else None, count\n",
    "    else:\n",
    "        return True, center_index, process_count\n",
    "\n",
    "data = list(range(1000))\n",
    "\n",
    "for _ in range(3):\n",
    "    val_to_search = random.randint(0, 999)\n",
    "    print(val_to_search, binary_search(data, val_to_search))\n",
    "\n",
    "print(binary_search(data, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-martial",
   "metadata": {},
   "source": [
    "## not recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(data, val):\n",
    "    \"\"\"data must be sorted\"\"\"\n",
    "    process_count = 0\n",
    "    start = 0\n",
    "    end = len(data) - 1\n",
    "    \n",
    "    while start <= end:\n",
    "        process_count += 1\n",
    "        center = (start + end) // 2\n",
    "        if val < data[center]:\n",
    "            end = center - 1\n",
    "        elif data[center] < val:\n",
    "            start = center + 1\n",
    "        else:\n",
    "            return True, center, process_count\n",
    "    return False, None, process_count\n",
    "\n",
    "data = list(range(1000))\n",
    "\n",
    "for _ in range(3):\n",
    "    val_to_search = random.randint(0, 999)\n",
    "    print(val_to_search, binary_search(data, val_to_search))\n",
    "\n",
    "print(binary_search(data, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-potential",
   "metadata": {},
   "source": [
    "# Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "        self.children = []\n",
    "        self.level = 0\n",
    "\n",
    "    def add_child(self, node):\n",
    "        node.level = self.level + 1\n",
    "        self.children.append(node)\n",
    "\n",
    "values = list(range(100))\n",
    "random.shuffle(values)\n",
    "value_queue = queue.Queue()\n",
    "for v in values:\n",
    "    value_queue.put(v)\n",
    "\n",
    "def add_children_to_one_node(parent_node, min_children=1, max_children=4):\n",
    "    num_of_children = random.randint(min_children, max_children)\n",
    "    for _ in range(num_of_children):\n",
    "        if value_queue.empty():\n",
    "            return\n",
    "        parent_node.add_child(Node(value_queue.get_nowait()))\n",
    "\n",
    "# add chilren by breadth first way, to create a balanced_tree-like tree\n",
    "def add_children_balancely(parent_node):\n",
    "    q = queue.Queue()\n",
    "    q.put(parent_node)\n",
    "    while not q.empty():\n",
    "        node = q.get_nowait()\n",
    "        add_children_to_one_node(node)\n",
    "        if value_queue.empty():\n",
    "            return\n",
    "        for child in node.children:\n",
    "            q.put(child)\n",
    "\n",
    "# this uses recursive way to add children, but this results in creating unbalanced treek\n",
    "def add_children_deeply(parent_node):\n",
    "    add_children_to_one_node(parent_node)\n",
    "    for child in parent_node.children:\n",
    "        add_children(child)\n",
    "        if value_queue.empty():\n",
    "            return\n",
    "\n",
    "root_node = Node(value_queue.get_nowait())\n",
    "add_children_balancely(root_node)\n",
    "# add_children_deeply(root_node)\n",
    "\n",
    "def print_node(node):\n",
    "    print(\"-\" * node.level + str(node.val))\n",
    "    for child in node.children:\n",
    "        print_node(child)\n",
    "\n",
    "print_node(root_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-island",
   "metadata": {},
   "source": [
    "## Depth First Search\n",
    "\n",
    "- use recursive or stack\n",
    "- advantage\n",
    "    - good memory performance\n",
    "    - 一筆書きできる\n",
    "- disadvanage\n",
    "    - takes time to exploring deep areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-johnston",
   "metadata": {},
   "source": [
    "### use recursive way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(root_node, val, print_=True):\n",
    "    trace_stack = queue.LifoQueue()\n",
    "    def search(node):\n",
    "        if print_:\n",
    "            print(\"-\" * node.level + str(node.val))\n",
    "        trace_stack.put(node)\n",
    "        if node.val == val:\n",
    "            return True\n",
    "        for child in node.children:\n",
    "            found = search(child)\n",
    "            if found:\n",
    "                return True\n",
    "        trace_stack.get_nowait()\n",
    "        return False\n",
    "\n",
    "    found = search(root_node)\n",
    "\n",
    "    if not found:\n",
    "        return False, None\n",
    "    traces = []\n",
    "    while not trace_stack.empty():\n",
    "        node = trace_stack.get_nowait()\n",
    "        traces.append(node)\n",
    "    traces.reverse()\n",
    "    return True, traces\n",
    "\n",
    "\n",
    "found, traces = depth_first_search(root_node, 50)\n",
    "print(\"========\")\n",
    "print(found)\n",
    "if found:\n",
    "    for node in traces:\n",
    "        print(node.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-helicopter",
   "metadata": {},
   "source": [
    "### use stack way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再帰の時のようにtraceをうまいこと残せない、、、もっと考えればうまい方法があるかも\n",
    "def depth_first_search(root_node, val, print_=True):\n",
    "    stack = queue.LifoQueue()\n",
    "    stack.put(root_node)\n",
    "    while not stack.empty():\n",
    "        node = stack.get_nowait()\n",
    "        if print_:\n",
    "            print(\"-\" * node.level + str(node.val))\n",
    "        if node.val == val:\n",
    "            return True\n",
    "        for child in reversed(node.children):\n",
    "            stack.put(child)\n",
    "    return False\n",
    "\n",
    "found = depth_first_search(root_node, 50)\n",
    "print(\"========\")\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-grace",
   "metadata": {},
   "source": [
    "## Breadth First Search\n",
    "\n",
    "- use queue\n",
    "- advantage\n",
    "    - okey if there are deep areas\n",
    "- disadvantage\n",
    "    - not good memory performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first_search(root_node, val, print_=True):\n",
    "    q = queue.Queue()\n",
    "    q.put(root_node)\n",
    "    while not q.empty():\n",
    "        node = q.get_nowait()\n",
    "        if print_:\n",
    "            print(\"-\" * node.level + str(node.val))\n",
    "        if node.val == val:\n",
    "            return True\n",
    "        for child in node.children:\n",
    "            q.put(child)\n",
    "    return False\n",
    "\n",
    "found = breadth_first_search(root_node, 50)\n",
    "print(\"========\")\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-chrome",
   "metadata": {},
   "source": [
    "# Sort\n",
    "\n",
    "### stable sort\n",
    "\n",
    "- 安定ソート\n",
    "- maintain the relative order of records with equal keys\n",
    "\n",
    "### in-place\n",
    "\n",
    "- 内部ソート\n",
    "- good memory perfomance: do not use other computer resources\n",
    "    - sort algorithm needing only $O(1)$ or $O(\\log{n})$ of other resources is considered \"in-place\"\n",
    "    - directly edit the memory region of data to be sorted, so this kind of algorithm does not need other resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-meeting",
   "metadata": {},
   "source": [
    "# Insertion Sort\n",
    "\n",
    "slow but in-place and stable sort.  \n",
    "very quick for almost sorted data.\n",
    "\n",
    "- $O(n^{2})$\n",
    "- stable sort\n",
    "- in-place\n",
    "- $O(n)$ for almost sorted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(data):\n",
    "    process_count = 0\n",
    "    for target_index in range(1, len(data)):\n",
    "        target_value = data[target_index]\n",
    "        j = target_index - 1\n",
    "        while 0 <= j and target_value < data[j]:\n",
    "            process_count += 1\n",
    "            data[j + 1] = data[j]\n",
    "            j -= 1\n",
    "        data[j + 1] = target_value\n",
    "    return process_count\n",
    "\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    process_count = insertion_sort(data)\n",
    "    print(process_count)\n",
    "\n",
    "print(\"==for almost sorted data==\")\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    partial = data[:995]\n",
    "    insertion_sort(partial)\n",
    "    data = partial + data[995:]\n",
    "    process_count = insertion_sort(data)\n",
    "    print(process_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-christmas",
   "metadata": {},
   "source": [
    "# Merge Sort\n",
    "\n",
    "Quick stable sort and very popular as well as Quick-Sort.  \n",
    "This is also called \"しめじソート\"\n",
    "\n",
    "- $O(n\\log{n})$\n",
    "    - same in the worst case\n",
    "- stable sort\n",
    "- **NOT** in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(entire_data):\n",
    "    process_count = 0\n",
    "    def sort(data):\n",
    "        nonlocal process_count\n",
    "        process_count += 1\n",
    "        if len(data) <= 1:\n",
    "            return\n",
    "        center_index = len(data) // 2\n",
    "        left = data[:center_index]\n",
    "        right = data[center_index:]\n",
    "\n",
    "        sort(left)\n",
    "        sort(right)\n",
    "\n",
    "        l_i = 0\n",
    "        r_i = 0\n",
    "\n",
    "        def use_right():\n",
    "            nonlocal r_i\n",
    "            data[i] = right[r_i]\n",
    "            r_i += 1\n",
    "        \n",
    "        def use_left():\n",
    "            nonlocal l_i\n",
    "            data[i] = left[l_i]\n",
    "            l_i += 1\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            process_count += 1\n",
    "            if len(left) <= l_i:\n",
    "                use_right()\n",
    "                continue\n",
    "            if len(right) <= r_i:\n",
    "                use_left()\n",
    "                continue\n",
    "            \n",
    "            if left[l_i] < right[r_i]:\n",
    "                use_left()\n",
    "            else:\n",
    "                use_right()\n",
    "    sort(entire_data)\n",
    "    return process_count\n",
    "\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    process_count = merge_sort(data)\n",
    "    print(process_count)\n",
    "\n",
    "print(\"==for almost sorted data==\")\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    partial = data[:995]\n",
    "    merge_sort(partial)\n",
    "    data = partial + data[995:]\n",
    "    process_count = merge_sort(data)\n",
    "    print(process_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-husband",
   "metadata": {},
   "source": [
    "# Quick Sort\n",
    "\n",
    "Quick in-place sort and very popular as well as Merge-Sort.\n",
    "\n",
    "- $O(n\\log{n})$\n",
    "    - $O(n^2)$ in the worst case\n",
    "- **NOT** stable sort\n",
    "- in-place\n",
    "\n",
    "挿入ソートが得意とするような、途中までほぼソートされているようなデータに対しては、  \n",
    "pivot選択をランダムにしないと桁が変わるレベルで遅くなることがわかる。  \n",
    "ランダムにすることで安定して $O(n\\log{n})$ の速度を出せている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_sort(data, randomize_pivot=False):\n",
    "    process_count = 0\n",
    "    def sort(start, end):\n",
    "        nonlocal process_count\n",
    "        if end <= start:\n",
    "            return\n",
    "        # The pivot should be selected randomly to get a stable speed.\n",
    "        # In that case, swapping pivot and the end value is needed. (pivot must be in the end position.)\n",
    "        if randomize_pivot:\n",
    "            pivot_i = random.randint(start, end)\n",
    "            data[pivot_i], data[end] = data[end], data[pivot_i]\n",
    "        pivot = data[end]\n",
    "\n",
    "        # i番目を確実にpivotよりも小さい数にしていく\n",
    "        # それがjを[start,end)まで1回しするだけで可能というのが要所(前提: end番目がpivot値。ランダムに選択する場合は事前にendとswapしておく)\n",
    "        # 仕組み\n",
    "        # - 基本iとjは並進する\n",
    "        # - i番目がすでにpivotよりも小さければ、i=jのまま同じ位置のswapが行われ、何も変化しないまま並進する\n",
    "        # - i番目がpivotよりも大きい場合にjがiよりも進み、pivotよりも小さい値を見つけるまで進み続ける\n",
    "        # - 見つかればi番目とj番目の値をswapすることで、やっとiも次に進める\n",
    "        # - 次のiの処理のために、jを戻す必要はない。なぜならこの時点で[i,j]範囲にpivotよりも小さい値は存在しえないから。\n",
    "        # - これをjがpivotに到達する前まで続ける。つまりjが[start,end)まで1回りする。\n",
    "        # - 以上が完了すると、i番目はpivot以上の値(ずっと並進しつづければiもpivotまで到達し、その際はpivot値になる)なので、i番目とpivotをswapする\n",
    "        # - 以上でi番目がpivotになり、[start,i-1]はすべてpivotより小さい値、[i+1,end]はすべてpivotより大きい値、に分割できたことになる\n",
    "        i = start\n",
    "        for j in range(start, end):\n",
    "            process_count += 1\n",
    "            if data[j] < pivot:\n",
    "                data[i], data[j] = data[j], data[i]\n",
    "                i += 1\n",
    "        data[i], data[end] = data[end], data[i]\n",
    "        sort(start, i - 1)\n",
    "        sort(i + 1, end)\n",
    "    sort(0, len(data) - 1)\n",
    "    return process_count\n",
    "\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    process_count = quick_sort(data)\n",
    "    print(process_count)\n",
    "\n",
    "print(\"==for almost sorted data==\")\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    partial = data[:995]\n",
    "    quick_sort(partial)\n",
    "    data = partial + data[995:]\n",
    "    process_count = quick_sort(data)\n",
    "    print(process_count)\n",
    "\n",
    "print()\n",
    "print(\"==randomized pivot==\")\n",
    "print()\n",
    "\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    process_count = quick_sort(data, randomize_pivot=True)\n",
    "    print(process_count)\n",
    "\n",
    "print(\"==for almost sorted data==\")\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    partial = data[:995]\n",
    "    quick_sort(partial)\n",
    "    data = partial + data[995:]\n",
    "    process_count = quick_sort(data, randomize_pivot=True)\n",
    "    print(process_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-omaha",
   "metadata": {},
   "source": [
    "# Heap Data Structure\n",
    "\n",
    "- different concept from the \"memory heap\"\n",
    "- a heap is a specialized tree-based data strucutre which satisfies the heap property.\n",
    "    - the heap property\n",
    "        - For any given node C, if P is a parent node of C, then the key(or the value) of P is greater than or equal to the key of C.\n",
    "- A common implementation of a heap is the \"binary heap\", in which the tree is a binary tree.\n",
    "- can be **represented in a array shape**\n",
    "    - the children of a[i] are a[2i+1] and a[2i+2]\n",
    "    - the parent of a[i] is a[(i-1)//2]\n",
    "- can get the max value in $O(1)$, because a[0] is always the max value\n",
    "- can remove the max value in $O(\\log{n})$\n",
    "    - swap a[0] with a[-1], and remove a[-1]\n",
    "    - swap the larger of a[1] and a[2] with a[0], and do this recursively to the swapped child node\n",
    "    - the height of the tree is $\\log{n}$, so this process is finished in $O(\\log{n})$\n",
    "\n",
    "通常はin-placeにしたいので、配列で2分木を表現し、配列内のswapだけで処理を行うことになる。  \n",
    "配列による2分木の表現方法を理解しておかないと何もわからないので注意。\n",
    "\n",
    "## ヒープの構築方法\n",
    "\n",
    "ヒープをfixする常套手法は、特定のノードについて再帰的に自分より大きい子ノードのうちより大きい方とswapを繰り返すこと。  \n",
    "これは既に構築されたヒープから最大値、つまりルートノードを除去する際に、ルートノードに対して行われる処理であり、この状態であればこれだけでヒープの再構築が完了する。  \n",
    "しかし一般的には、子ノードが自分よりも小さくなるように他のヒープを崩さず修正するだけに過ぎず、意図がつかみにくい処理に見えてしまう。  \n",
    "\n",
    "\n",
    "以下のポイントを理解すれば、ロジックが腹に落ちるはず。\n",
    "\n",
    "- 最大値を順番に取得するためにヒープを用いる文脈では、最大値を除去する処理が最重要\n",
    "- ルートノード以外の調整や、ヒープを1から構築するには、この処理を後ろ側から繰り返すだけで良い\n",
    "    - 後半は末端の子なしノードにきまっているので、 n//2 から 0 に向かって繰り返せば十分\n",
    "\n",
    "後ろ側から繰り返せば全体をヒープにできる、というのは最初は納得しがたいかもしれないが、少なくとも1代しか子供を持たない末端親ノードについては、この処理を行うことでその位置以下の部分をヒープ構造にできたことになる(当たり前)。  \n",
    "これを考えれば下から1段ずつ上に向かって処理を繰り返していけば、もれなくヒープ構造を広げていけるのは想像しやすいはず。  \n",
    "頭から繰り返すとなぜダメなのか、ちゃんと考えればわかるかもだが、まあ確かに後ろからやった方がイメージしやすいというレベルの理解。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 他のヒープ構造を崩さず、特定のノードについて子ノードが自分よりも小さくなるよう構造を修正する、ヒープ最重要ロジック\n",
    "# 末端親ノードからルートノードまで順番に行うことで全体をヒープにできる\n",
    "# 既にヒープ構造の場合は、ルートノード、つまり最大値を除去した後の再構築に利用できる\n",
    "# (末端のノードとルートをスワップし、スワップ済みのヒープが崩れたルートに対してこれを1回行えばいい)\n",
    "# lengthを指定することで処理する領域を制限する。ソートに用いる場合に利用することになる。\n",
    "def heap_one_node(data, i, length=None, process_count=0):\n",
    "    if length is None:\n",
    "        length = len(data)\n",
    "    largest = i\n",
    "    left = 2 * i + 1\n",
    "    right = 2 * i + 2\n",
    "    if left < length and data[i] < data[left]:\n",
    "        largest = left\n",
    "    if right < length and data[largest] < data[right]:\n",
    "        largest = right\n",
    "    if largest != i:\n",
    "        data[i], data[largest] = data[largest], data[i]\n",
    "        process_count = heap_one_node(data, largest, length, process_count + 1)\n",
    "    return process_count\n",
    "\n",
    "def heap_all(data):\n",
    "    process_count = 0\n",
    "    for i in range(len(data)//2, -1, -1):\n",
    "        count = heap_one_node(data, i)\n",
    "        process_count += count + 1\n",
    "    return process_count\n",
    "\n",
    "data = list(range(10))\n",
    "random.shuffle(data)\n",
    "heap_all(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-independence",
   "metadata": {},
   "source": [
    "# Heap Sort\n",
    "\n",
    "Quick in-place sort as well as Quick-Sort, but inferior to Quick-Sort in average speed.\n",
    "\n",
    "- $O(n\\log{n})$\n",
    "    - same in the worst case\n",
    "- **NOT** stable sort\n",
    "- in-place\n",
    "\n",
    "なぜかQuick-Sortよりも若干少ないループ回数がでた。本当はQuick-Sortの方が平均的には速いらしい。  \n",
    "カウントの仕方か何かが間違っている可能性がある、、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heap_sort(data):\n",
    "    process_count = 0\n",
    "    count = heap_all(data)\n",
    "    process_count += count\n",
    "    for i in range(len(data) - 1, 0, -1):\n",
    "        data[0], data[i] = data[i], data[0]\n",
    "        count = heap_one_node(data, 0, i)\n",
    "        process_count += count + 1\n",
    "    return process_count\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    process_count = heap_sort(data)\n",
    "    print(process_count)\n",
    "\n",
    "print(\"==for almost sorted data==\")\n",
    "for _ in range(5):\n",
    "    data = list(range(1000))\n",
    "    random.shuffle(data)\n",
    "    partial = data[:995]\n",
    "    heap_sort(partial)\n",
    "    data = partial + data[995:]\n",
    "    process_count = heap_sort(data)\n",
    "    print(process_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-drama",
   "metadata": {},
   "source": [
    "# Bucket Sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-lyric",
   "metadata": {},
   "source": [
    "# Selection Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-conversation",
   "metadata": {},
   "source": [
    "# Bubble Sort"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
